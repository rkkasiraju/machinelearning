## Introduction to Model Evaluation Metrics

As mentioned, basically, we can compare the actual values and predicted values to calculate the accuracy of our regression model. Evaluation metrics provide a key role in the development of a model as it provides insight into areas that require improvement. We'll be reviewing a number of model evaluation metrics, including Mean Absolute Error, Mean Squared Error, and Root Mean Squared Error, but before we get into defining these, we need to define what an error actually is.

## What Is Error in Regression?

In the context of regression, the error of the model is the difference between the data points and the trend line generated by the algorithm. Since there are multiple data points, an error can be determined in multiple ways.

## Mean Absolute Error (MAE)

Mean Absolute Error is the mean of the absolute value of the errors. This is the easiest of the metrics to understand, since it's just the average error.

## Mean Squared Error (MSE)

Mean Squared Error is the mean of the squared error. It's more popular than Mean Absolute Error because the focus is geared more towards large errors. This is due to the squared term, exponentially increasing larger errors in comparison to smaller ones.

## Root Mean Squared Error (RMSE)

Root Mean Squared Error is the square root of the Mean Squared Error. This is one of the most popular of the evaluation metrics because Root Mean Squared Error is interpretable in the same units as the response vector or Y units, making it easy to relate its information.

## Relative Absolute Error

Relative Absolute Error, also known as residual sum of squares, where Y bar is a mean value of Y, takes the total absolute error and normalizes it. By dividing by the total absolute error of the simple predictor.

## Relative Squared Error

Relative Squared Error is very similar to Relative Absolute Error, but is widely adopted by the data science community as it is used for calculating R-squared.

## R-squared (RÂ²)

R-squared is not an error per se but is a popular metric for the accuracy of your model. It represents how close the data values are to the fitted regression line. The higher the R-squared, the better the model fits your data.

Each of these metrics can be used for quantifying your prediction. The choice of metric completely depends on the type of model, your data type, and domain knowledge. Unfortunately, further review is out of scope for this course.
